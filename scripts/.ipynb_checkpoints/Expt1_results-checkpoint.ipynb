{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('prep')\n",
    "from req_fns import resampling_statistics1d, calculate_aprime, runAnalyses, likelihood_betaBinom\n",
    "os.chdir('../') \n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project directory \n",
    "base_project_dir= os.getcwd()\n",
    "project_dir = '../expt1/'\n",
    "results_dir = project_dir + 'results/'\n",
    "attndat = pd.read_csv(results_dir + 'expt1_attn_results.csv')\n",
    "wmdat = pd.read_csv(results_dir + 'expt1_wm_results.csv')\n",
    "\n",
    "all_subj = np.unique(attndat.subject_num)\n",
    "nsubj = np.size(all_subj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate behavioral and pupillary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of lure trials, acc = 56.86 3.04\n",
      "accuracy of non-lure trials, acc = 95.59 0.85\n",
      "pupil size during lure trials, s = 29.36 4.6\n",
      "pupil size during non-lure trials s = -0.03 3.42\n",
      "pupil size during accurate lure trials, s = 26.2 4.97\n",
      "pupil size during accurate non-lure trials, s = -0.51 3.43\n",
      "attention sensitivity, A' = 0.86 0.01\n",
      "wm performance, m = 2.24 0.11\n",
      "pupil size during retention interval, s = 49.55 8.12\n"
     ]
    }
   ],
   "source": [
    "#behavioral accuracy\n",
    "acc_nonlure = np.array([ np.mean(attndat.acc[np.logical_and(attndat.freq_trials==1,attndat.subject_num==isubj)]==1) for isubj in range(nsubj)])\n",
    "acc_lure = np.array([ np.mean(attndat.acc[np.logical_and(attndat.freq_trials==0,attndat.subject_num==isubj)]==1) for isubj in range(nsubj)])\n",
    "print(\"accuracy of lure trials, acc =\", np.round(np.mean((acc_lure)*100),decimals=2),np.round(np.std((acc_lure)*100)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"accuracy of non-lure trials, acc =\", np.round(np.mean(acc_nonlure*100),decimals=2),np.round(np.std(acc_nonlure*100)/np.sqrt(nsubj),decimals=2))\n",
    "\n",
    "#pupil size\n",
    "s_lure = np.array([ np.mean(attndat.s_post[np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==0,attndat.subject_num==isubj),attndat.arf==0)]-attndat.s_bl[np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==0,attndat.subject_num==isubj),attndat.arf==0)]) for isubj in range(nsubj)])\n",
    "s_nonlure = np.array([ np.mean(attndat.s_post[np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==1,attndat.subject_num==isubj),attndat.arf==0)]-attndat.s_bl[np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==1,attndat.subject_num==isubj),attndat.arf==0)]) for isubj in range(nsubj)])\n",
    "print(\"pupil size during lure trials, s =\", np.round(np.mean(s_lure),decimals=2),np.round(np.std(s_lure)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"pupil size during non-lure trials s =\", np.round(np.mean(s_nonlure),decimals=2),np.round(np.std(s_nonlure)/np.sqrt(nsubj),decimals=2))\n",
    "\n",
    "#pupil size, accurate trials only\n",
    "s_lure_acc = np.array([ np.mean(attndat.s_post[np.logical_and(np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==0,attndat.subject_num==isubj),attndat.arf==0),attndat.acc==1)]-attndat.s_bl[np.logical_and(np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==0,attndat.subject_num==isubj),attndat.arf==0),attndat.acc==1)]) for isubj in range(nsubj)])\n",
    "s_nonlure_acc = np.array([ np.mean(attndat.s_post[np.logical_and(np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==1,attndat.subject_num==isubj),attndat.arf==0),attndat.acc==1)]-attndat.s_bl[np.logical_and(np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==1,attndat.subject_num==isubj),attndat.arf==0),attndat.acc==1)]) for isubj in range(nsubj)])\n",
    "print(\"pupil size during accurate lure trials, s =\", np.round(np.mean(s_lure_acc),decimals=2),np.round(np.std(s_lure_acc)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"pupil size during accurate non-lure trials, s =\", np.round(np.mean(s_nonlure_acc),decimals=2),np.round(np.std(s_nonlure_acc)/np.sqrt(nsubj),decimals=2))\n",
    "\n",
    "#aprime\n",
    "aprime = calculate_aprime(acc_nonlure,1-acc_lure)\n",
    "print(\"attention sensitivity, A' =\", np.round(np.mean(aprime),decimals=2),np.round(np.std(aprime)/np.sqrt(nsubj),decimals=2))\n",
    "\n",
    "#wm performance\n",
    "wmacc = np.array([ np.mean(wmdat.wm_perf[wmdat.subject_num==isubj]) for isubj in range(nsubj)])\n",
    "print(\"wm performance, m =\", np.round(np.mean(wmacc,axis=0),decimals=2),np.round(np.nanstd(wmacc)/np.sqrt(nsubj),decimals=2))\n",
    "\n",
    "#pupil size, retention intervla\n",
    "s_ret = np.array([ np.nanmean(wmdat.s_ret[np.logical_and(wmdat.subject_num==isubj,wmdat.arf==0)]-\n",
    "                           wmdat.s_prevstim_bl[np.logical_and(wmdat.subject_num==isubj,wmdat.arf==0)]) for isubj in range(nsubj)])\n",
    "print(\"pupil size during retention interval, s =\", np.round(np.nanmean(s_ret),decimals=2),np.round(np.std(s_ret)/np.sqrt(nsubj),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.81 +/- 0.23\n",
      "kmax:  2.83 +/- 0.12\n"
     ]
    }
   ],
   "source": [
    "alpha_vals = np.arange(.01,10,.01)\n",
    "kmax_vals = np.arange(1,7,dtype=int)\n",
    "alpha = np.empty(nsubj)\n",
    "kmax = np.empty(nsubj)\n",
    "for isubj in range(nsubj):\n",
    "    alpha[isubj], kmax[isubj], _, _, _, _ = runAnalyses(wmdat.wm_perf[wmdat.subject_num==isubj], \n",
    "                                                        likelihood_betaBinom, alpha_vals, kmax_vals)\n",
    "\n",
    "print(\"alpha: \", np.round(np.mean(alpha),decimals=2),\"+/-\",np.round(np.std(alpha)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"kmax: \", np.round(np.mean(kmax),decimals=2),\"+/-\",np.round(np.std(kmax)/np.sqrt(nsubj),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr, wmacc pupil size during retention, r=  0.62 p= 0.0003\n"
     ]
    }
   ],
   "source": [
    "#correlate working memory and pupil size\n",
    "r,p = spearmanr(wmacc,s_ret)\n",
    "print('corr, wmacc pupil size during retention, r= ', np.round(r,decimals=2), 'p=', np.round(p,decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT before lapses vs non lapses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT before inaccurate: 324.0 +/- 40.0\n",
      "RT before accurate: 444.0 +/- 48.0\n"
     ]
    }
   ],
   "source": [
    "rttrail_inacc = np.array([ np.mean(attndat.rt_trail[np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==0,attndat.subject_num==isubj),attndat.acc!=1)])*1000 for isubj in range(nsubj)])\n",
    "rttrail_acc = np.array([ np.mean(attndat.rt_trail[np.logical_and(np.logical_and(\n",
    "    attndat.freq_trials==0,attndat.subject_num==isubj),attndat.acc==1)])*1000 for isubj in range(nsubj)])\n",
    "\n",
    "print(\"RT before inaccurate:\", np.round(np.mean(rttrail_inacc)),\"+/-\",np.round(np.std(rttrail_inacc)))\n",
    "print(\"RT before accurate:\",np.round(np.mean(rttrail_acc)),\"+/-\",np.round(np.std(rttrail_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral real time triggering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT fast 240.0 +/- 8.0\n",
      "RT slow 519.0 +/- 13.0\n"
     ]
    }
   ],
   "source": [
    "#RT\n",
    "rt_trail_low = np.array([ np.mean(wmdat.rt_trail[((np.logical_and(\n",
    "    wmdat.triggered_low==1,wmdat.subject_num==isubj)))])*1000 for isubj in range(nsubj)])\n",
    "rt_trail_high = np.array([ np.mean(wmdat.rt_trail[((np.logical_and(\n",
    "    wmdat.triggered_high==1,wmdat.subject_num==isubj)))])*1000 for isubj in range(nsubj)])\n",
    "print(\"RT low\",np.round(np.mean(rt_trail_low),decimals=0),\"+/-\",np.round(np.std(rt_trail_low)/np.sqrt(nsubj),decimals=0))\n",
    "print(\"RT high\", np.round(np.mean(rt_trail_high),decimals=0),\"+/-\",np.round(np.std(rt_trail_high)/np.sqrt(nsubj),decimals=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m low 2.2 +/- 0.1\n",
      "m high 2.29 +/- 0.11\n",
      "p = 0.03\n"
     ]
    }
   ],
   "source": [
    "#working memory\n",
    "m_low = np.array([ np.mean(wmdat.wm_perf[((np.logical_and(\n",
    "    wmdat.triggered_low==1,wmdat.subject_num==isubj)))]) for isubj in range(nsubj)])\n",
    "m_high = np.array([ np.mean(wmdat.wm_perf[((np.logical_and(\n",
    "    wmdat.triggered_high==1,wmdat.subject_num==isubj)))]) for isubj in range(nsubj)])\n",
    "print(\"m low\", np.round(np.mean(m_low),decimals=2),\"+/-\",np.round(np.std(m_low)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"m high\", np.round(np.mean(m_high),decimals=2),\"+/-\",np.round(np.std(m_high)/np.sqrt(nsubj),decimals=2))\n",
    "p,_ = resampling_statistics1d(m_high-m_low,0)\n",
    "print(\"p =\",np.round(p,decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s trail low -9.12 +/- 5.22\n",
      "s trail high 9.05 +/- 5.45\n",
      "p = 0.04\n"
     ]
    }
   ],
   "source": [
    "#pupil size\n",
    "strail_m = np.array([ np.mean(wmdat.s_prevstim[np.logical_and(\n",
    "    wmdat.subject_num==isubj,np.logical_or(wmdat.triggered_high==1,wmdat.triggered_low==1))]) for isubj in range(nsubj)])\n",
    "strail_high = np.array([ np.mean(wmdat.s_prevstim[(np.logical_and(\n",
    "    wmdat.subject_num==isubj,wmdat.triggered_high==1))]) for isubj in range(nsubj)])\n",
    "strail_low = np.array([ np.mean(wmdat.s_prevstim[(np.logical_and(\n",
    "    wmdat.subject_num==isubj,wmdat.triggered_low==1))]) for isubj in range(nsubj)])\n",
    "print(\"s trail low\", np.round(np.mean(strail_low-strail_m,axis=0),decimals=2),\"+/-\",\n",
    "      np.round(np.std(strail_low-strail_m,axis=0)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"s trail high\", np.round(np.mean(strail_high-strail_m,axis=0),decimals=2),\"+/-\",\n",
    "      np.round(np.std(strail_high-strail_m,axis=0)/np.sqrt(nsubj),decimals=2))\n",
    "p,_ = resampling_statistics1d(strail_high-strail_low,0)\n",
    "print(\"p =\",np.round(p,decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s trail low -13.96 +/- 5.67\n",
      "s trail high 14.67 +/- 6.41\n",
      "p = 0.008\n"
     ]
    }
   ],
   "source": [
    "#pupil size, after artifact rejecting\n",
    "strail_m = np.array([ np.mean(wmdat.s_prevstim[np.logical_and(np.logical_and(\n",
    "    wmdat.subject_num==isubj,np.logical_or(wmdat.triggered_high==1,\n",
    "    wmdat.triggered_low==1)),wmdat.arf==0)]) for isubj in range(nsubj)])\n",
    "strail_high = np.array([ np.mean(wmdat.s_prevstim[np.logical_and(np.logical_and(\n",
    "    wmdat.subject_num==isubj,wmdat.triggered_high==1),wmdat.arf==0)]) for isubj in range(nsubj)])\n",
    "strail_low = np.array([ np.mean(wmdat.s_prevstim[np.logical_and(np.logical_and(\n",
    "    wmdat.subject_num==isubj,wmdat.triggered_low==1),wmdat.arf==0)]) for isubj in range(nsubj)])\n",
    "print(\"s trail low\", np.round(np.mean(strail_low-strail_m,axis=0),decimals=2),\"+/-\",\n",
    "      np.round(np.std(strail_low-strail_m,axis=0)/np.sqrt(nsubj),decimals=2))\n",
    "print(\"s trail high\", np.round(np.mean(strail_high-strail_m,axis=0),decimals=2),\"+/-\",\n",
    "      np.round(np.std(strail_high-strail_m,axis=0)/np.sqrt(nsubj),decimals=2))\n",
    "p,_ = resampling_statistics1d(strail_high-strail_low,0)\n",
    "print(\"p =\",np.round(p,decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/megan/Dropbox/writing/articles/2020_pupil/KeenedeBettencourt_2021/scripts'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
